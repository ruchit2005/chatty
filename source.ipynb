{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8e7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "api_url = \"https://router.huggingface.co/hf-inference/models/mistralai/Mistral-7B-Instruct-v0.3/v1/chat/completions\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a04c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Downloading vllm-0.8.5.post1.tar.gz (7.3 MB)\n",
      "     ---------------------------------------- 0.0/7.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 7.3/7.3 MB 64.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting cachetools (from vllm)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: psutil in d:\\conda\\envs\\chatty\\lib\\site-packages (from vllm) (5.9.5)\n",
      "Collecting sentencepiece (from vllm)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy in d:\\conda\\envs\\chatty\\lib\\site-packages (from vllm) (2.2.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from vllm) (2.32.3)\n",
      "Requirement already satisfied: tqdm in d:\\conda\\envs\\chatty\\lib\\site-packages (from vllm) (4.67.1)\n",
      "Collecting blake3 (from vllm)\n",
      "  Downloading blake3-1.0.5-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting transformers>=4.51.1 (from vllm)\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from huggingface-hub[hf_xet]>=0.30.0->vllm) (0.31.4)\n",
      "Collecting tokenizers>=0.21.1 (from vllm)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting protobuf (from vllm)\n",
      "  Downloading protobuf-6.31.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting aiohttp (from vllm)\n",
      "  Downloading aiohttp-3.11.18-cp310-cp310-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting openai>=1.52.0 (from vllm)\n",
      "  Downloading openai-1.81.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic>=2.9 in d:\\conda\\envs\\chatty\\lib\\site-packages (from vllm) (2.11.4)\n",
      "Collecting prometheus_client>=0.18.0 (from vllm)\n",
      "  Using cached prometheus_client-0.22.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pillow (from vllm)\n",
      "  Downloading pillow-11.2.1-cp310-cp310-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
      "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n",
      "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting outlines==0.1.11 (from vllm)\n",
      "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lark==1.2.2 (from vllm)\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in d:\\conda\\envs\\chatty\\lib\\site-packages (from vllm) (4.13.2)\n",
      "Requirement already satisfied: filelock>=3.16.1 in d:\\conda\\envs\\chatty\\lib\\site-packages (from vllm) (3.18.0)\n",
      "Collecting partial-json-parser (from vllm)\n",
      "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from vllm) (25.0.2)\n",
      "Collecting msgspec (from vllm)\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting gguf>=0.13.0 (from vllm)\n",
      "  Downloading gguf-0.16.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: importlib_metadata in d:\\conda\\envs\\chatty\\lib\\site-packages (from vllm) (8.6.1)\n",
      "Collecting mistral_common>=1.5.4 (from mistral_common[opencv]>=1.5.4->vllm)\n",
      "  Downloading mistral_common-1.5.5-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pyyaml in d:\\conda\\envs\\chatty\\lib\\site-packages (from vllm) (6.0.2)\n",
      "Collecting einops (from vllm)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting compressed-tensors==0.9.3 (from vllm)\n",
      "  Downloading compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting depyf==0.18.0 (from vllm)\n",
      "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting cloudpickle (from vllm)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchfiles (from vllm)\n",
      "  Downloading watchfiles-1.0.5-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting python-json-logger (from vllm)\n",
      "  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting scipy (from vllm)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Using cached ninja-1.11.1.4-py3-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting opentelemetry-sdk<1.27.0,>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api<1.27.0,>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp<1.27.0,>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 (from vllm)\n",
      "  Downloading opentelemetry_semantic_conventions_ai-0.4.9-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting torch>=1.7.0 (from compressed-tensors==0.9.3->vllm)\n",
      "  Downloading torch-2.7.0-cp310-cp310-win_amd64.whl.metadata (29 kB)\n",
      "Collecting astor (from depyf==0.18.0->vllm)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dill (from depyf==0.18.0->vllm)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting interegular (from outlines==0.1.11->vllm)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jinja2 in d:\\conda\\envs\\chatty\\lib\\site-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in d:\\conda\\envs\\chatty\\lib\\site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "Collecting diskcache (from outlines==0.1.11->vllm)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting referencing (from outlines==0.1.11->vllm)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting jsonschema (from outlines==0.1.11->vllm)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting pycountry (from outlines==0.1.11->vllm)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
      "  Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
      "  Downloading outlines_core-0.1.26-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: packaging in d:\\conda\\envs\\chatty\\lib\\site-packages (from lm-format-enforcer<0.11,>=0.10.11->vllm) (25.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<1.27.0,>=1.26.0->vllm)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib_metadata (from vllm)\n",
      "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\conda\\envs\\chatty\\lib\\site-packages (from importlib_metadata->vllm) (3.21.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio<2.0.0,>=1.0.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
      "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from vllm)\n",
      "  Downloading protobuf-4.25.7-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm)\n",
      "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\conda\\envs\\chatty\\lib\\site-packages (from requests>=2.26.0->vllm) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\conda\\envs\\chatty\\lib\\site-packages (from requests>=2.26.0->vllm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\conda\\envs\\chatty\\lib\\site-packages (from requests>=2.26.0->vllm) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\conda\\envs\\chatty\\lib\\site-packages (from requests>=2.26.0->vllm) (2025.4.26)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\conda\\envs\\chatty\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.17.2)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\conda\\envs\\chatty\\lib\\site-packages (from pydantic>=2.9->vllm) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from pydantic>=2.9->vllm) (0.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in d:\\conda\\envs\\chatty\\lib\\site-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\conda\\envs\\chatty\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\conda\\envs\\chatty\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (1.3.1)\n",
      "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: typer>=0.12.3 in d:\\conda\\envs\\chatty\\lib\\site-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.4)\n",
      "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rich_toolkit-0.14.6-py3-none-any.whl.metadata (999 bytes)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\conda\\envs\\chatty\\lib\\site-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\conda\\envs\\chatty\\lib\\site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->vllm) (2025.5.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.1 (from huggingface-hub[hf_xet]>=0.30.0->vllm)\n",
      "  Downloading hf_xet-1.1.2-cp37-abi3-win_amd64.whl.metadata (883 bytes)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
      "Collecting attrs>=22.2.0 (from jsonschema->outlines==0.1.11->vllm)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->outlines==0.1.11->vllm)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->outlines==0.1.11->vllm)\n",
      "  Downloading rpds_py-0.25.1-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.52.0->vllm)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.52.0->vllm)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: click>=8.1.7 in d:\\conda\\envs\\chatty\\lib\\site-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (8.1.8)\n",
      "Requirement already satisfied: rich>=13.7.1 in d:\\conda\\envs\\chatty\\lib\\site-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.0.0)\n",
      "Requirement already satisfied: colorama in d:\\conda\\envs\\chatty\\lib\\site-packages (from click>=8.1.7->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.4.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\conda\\envs\\chatty\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.6.0->vllm)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.7.0->compressed-tensors==0.9.3->vllm)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.7.0->compressed-tensors==0.9.3->vllm)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.7.0->compressed-tensors==0.9.3->vllm)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.51.1->vllm)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\conda\\envs\\chatty\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in d:\\conda\\envs\\chatty\\lib\\site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.0)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->vllm)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->vllm)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->vllm)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->vllm)\n",
      "  Downloading frozenlist-1.6.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->vllm)\n",
      "  Downloading multidict-6.4.4-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->vllm)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->vllm)\n",
      "  Downloading yarl-1.20.0-cp310-cp310-win_amd64.whl.metadata (74 kB)\n",
      "Downloading compressed_tensors-0.9.3-py3-none-any.whl (98 kB)\n",
      "Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "Downloading outlines_core-0.1.26-cp310-cp310-win_amd64.whl (243 kB)\n",
      "Downloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
      "Downloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
      "Downloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
      "Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 64.8 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
      "Downloading opentelemetry_semantic_conventions_ai-0.4.9-py3-none-any.whl (5.6 kB)\n",
      "Downloading protobuf-4.25.7-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
      "Downloading gguf-0.16.3-py3-none-any.whl (94 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 991.5/991.5 kB 45.6 MB/s eta 0:00:00\n",
      "Downloading hf_xet-1.1.2-cp37-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 79.9 MB/s eta 0:00:00\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading mistral_common-1.5.5-py3-none-any.whl (6.5 MB)\n",
      "   ---------------------------------------- 0.0/6.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.5/6.5 MB 98.7 MB/s eta 0:00:00\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading openai-1.81.0-py3-none-any.whl (717 kB)\n",
      "   ---------------------------------------- 0.0/717.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 717.5/717.5 kB 30.4 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "   ---------------------------------------- 0.0/39.4 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 14.9/39.4 MB 78.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 16.5/39.4 MB 43.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 17.6/39.4 MB 29.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 18.9/39.4 MB 23.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 20.4/39.4 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 22.3/39.4 MB 17.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 24.1/39.4 MB 16.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 26.5/39.4 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 29.1/39.4 MB 15.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.7/39.4 MB 15.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.9/39.4 MB 15.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.3/39.4 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.4/39.4 MB 15.0 MB/s eta 0:00:00\n",
      "Downloading pillow-11.2.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 17.1 MB/s eta 0:00:00\n",
      "Using cached prometheus_client-0.22.0-py3-none-any.whl (62 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rich_toolkit-0.14.6-py3-none-any.whl (24 kB)\n",
      "Downloading rpds_py-0.25.1-cp310-cp310-win_amd64.whl (231 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.0/894.0 kB 13.4 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 17.4 MB/s eta 0:00:00\n",
      "Downloading torch-2.7.0-cp310-cp310-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 3.9/212.5 MB 19.5 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 8.4/212.5 MB 20.0 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 12.8/212.5 MB 20.1 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 17.3/212.5 MB 21.0 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 22.3/212.5 MB 21.3 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 27.8/212.5 MB 22.0 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 33.3/212.5 MB 22.7 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 38.8/212.5 MB 23.3 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 44.6/212.5 MB 24.0 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 50.6/212.5 MB 24.4 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 57.4/212.5 MB 25.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 63.7/212.5 MB 25.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 70.8/212.5 MB 26.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 72.9/212.5 MB 25.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 74.4/212.5 MB 24.0 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 76.0/212.5 MB 23.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 78.1/212.5 MB 22.1 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 80.5/212.5 MB 21.4 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 82.6/212.5 MB 20.9 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 85.2/212.5 MB 20.5 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 88.1/212.5 MB 20.1 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 91.5/212.5 MB 19.9 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 94.9/212.5 MB 19.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 98.8/212.5 MB 19.7 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 102.8/212.5 MB 19.6 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 106.7/212.5 MB 19.6 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 110.9/212.5 MB 19.7 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 115.3/212.5 MB 19.7 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 120.3/212.5 MB 19.9 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 125.6/212.5 MB 20.0 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 131.3/212.5 MB 20.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 136.8/212.5 MB 20.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 142.6/212.5 MB 20.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 148.9/212.5 MB 20.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 155.5/212.5 MB 21.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 162.5/212.5 MB 21.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 169.3/212.5 MB 21.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 174.6/212.5 MB 21.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 177.5/212.5 MB 21.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 180.1/212.5 MB 21.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 183.2/212.5 MB 21.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 186.6/212.5 MB 21.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 190.1/212.5 MB 21.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 193.7/212.5 MB 21.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 197.9/212.5 MB 20.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 202.1/212.5 MB 20.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 206.8/212.5 MB 21.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  211.3/212.5 MB 21.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 21.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 20.6 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 5.0/6.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 22.8 MB/s eta 0:00:00\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 5.2/10.5 MB 26.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 26.1 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Downloading watchfiles-1.0.5-cp310-cp310-win_amd64.whl (291 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Downloading aiohttp-3.11.18-cp310-cp310-win_amd64.whl (442 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.4.4-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Downloading yarl-1.20.0-cp310-cp310-win_amd64.whl (92 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp310-cp310-win_amd64.whl (120 kB)\n",
      "Downloading propcache-0.3.1-cp310-cp310-win_amd64.whl (45 kB)\n",
      "Downloading airportsdata-20250224-py3-none-any.whl (913 kB)\n",
      "   ---------------------------------------- 0.0/913.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 913.7/913.7 kB 21.0 MB/s eta 0:00:00\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading blake3-1.0.5-cp310-cp310-win_amd64.whl (222 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading msgspec-0.19.0-cp310-cp310-win_amd64.whl (186 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached ninja-1.11.1.4-py3-none-win_amd64.whl (296 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 5.8/6.3 MB 27.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 26.0 MB/s eta 0:00:00\n",
      "Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 6.0/41.3 MB 28.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 12.3/41.3 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 18.9/41.3 MB 30.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 26.0/41.3 MB 31.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.8/41.3 MB 31.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.4/41.3 MB 29.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.4/41.3 MB 27.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 26.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: vllm\n",
      "  Building wheel for vllm (pyproject.toml): started\n",
      "  Building wheel for vllm (pyproject.toml): finished with status 'error'\n",
      "Failed to build vllm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for vllm (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1578 lines of output]\n",
      "      C:\\Users\\Mitul Gupta\\AppData\\Local\\Temp\\pip-build-env-x1w8aa4m\\overlay\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:81.)\n",
      "        cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "      vLLM only supports Linux platform (including WSL) and MacOS.Building on win32, so vLLM may not be able to run correctly\n",
      "      C:\\Users\\Mitul Gupta\\AppData\\Local\\Temp\\pip-build-env-x1w8aa4m\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
      "      \n",
      "              By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        corresp(dist, value, root_dir)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib\\vllm\n",
      "      copying vllm\\beam_search.py -> build\\lib\\vllm\n",
      "      copying vllm\\collect_env.py -> build\\lib\\vllm\n",
      "      copying vllm\\config.py -> build\\lib\\vllm\n",
      "      copying vllm\\connections.py -> build\\lib\\vllm\n",
      "      copying vllm\\envs.py -> build\\lib\\vllm\n",
      "      copying vllm\\env_override.py -> build\\lib\\vllm\n",
      "      copying vllm\\forward_context.py -> build\\lib\\vllm\n",
      "      copying vllm\\jsontree.py -> build\\lib\\vllm\n",
      "      copying vllm\\logger.py -> build\\lib\\vllm\n",
      "      copying vllm\\logits_process.py -> build\\lib\\vllm\n",
      "      copying vllm\\outputs.py -> build\\lib\\vllm\n",
      "      copying vllm\\pooling_params.py -> build\\lib\\vllm\n",
      "      copying vllm\\sampling_params.py -> build\\lib\\vllm\n",
      "      copying vllm\\scalar_type.py -> build\\lib\\vllm\n",
      "      copying vllm\\scripts.py -> build\\lib\\vllm\n",
      "      copying vllm\\sequence.py -> build\\lib\\vllm\n",
      "      copying vllm\\test_utils.py -> build\\lib\\vllm\n",
      "      copying vllm\\tracing.py -> build\\lib\\vllm\n",
      "      copying vllm\\utils.py -> build\\lib\\vllm\n",
      "      copying vllm\\version.py -> build\\lib\\vllm\n",
      "      copying vllm\\_custom_ops.py -> build\\lib\\vllm\n",
      "      copying vllm\\_ipex_ops.py -> build\\lib\\vllm\n",
      "      copying vllm\\_version.py -> build\\lib\\vllm\n",
      "      copying vllm\\__init__.py -> build\\lib\\vllm\n",
      "      creating build\\lib\\vllm\\adapter_commons\n",
      "      copying vllm\\adapter_commons\\layers.py -> build\\lib\\vllm\\adapter_commons\n",
      "      copying vllm\\adapter_commons\\models.py -> build\\lib\\vllm\\adapter_commons\n",
      "      copying vllm\\adapter_commons\\request.py -> build\\lib\\vllm\\adapter_commons\n",
      "      copying vllm\\adapter_commons\\utils.py -> build\\lib\\vllm\\adapter_commons\n",
      "      copying vllm\\adapter_commons\\worker_manager.py -> build\\lib\\vllm\\adapter_commons\n",
      "      copying vllm\\adapter_commons\\__init__.py -> build\\lib\\vllm\\adapter_commons\n",
      "      creating build\\lib\\vllm\\assets\n",
      "      copying vllm\\assets\\audio.py -> build\\lib\\vllm\\assets\n",
      "      copying vllm\\assets\\base.py -> build\\lib\\vllm\\assets\n",
      "      copying vllm\\assets\\image.py -> build\\lib\\vllm\\assets\n",
      "      copying vllm\\assets\\video.py -> build\\lib\\vllm\\assets\n",
      "      copying vllm\\assets\\__init__.py -> build\\lib\\vllm\\assets\n",
      "      creating build\\lib\\vllm\\attention\n",
      "      copying vllm\\attention\\layer.py -> build\\lib\\vllm\\attention\n",
      "      copying vllm\\attention\\selector.py -> build\\lib\\vllm\\attention\n",
      "      copying vllm\\attention\\__init__.py -> build\\lib\\vllm\\attention\n",
      "      creating build\\lib\\vllm\\benchmarks\n",
      "      copying vllm\\benchmarks\\datasets.py -> build\\lib\\vllm\\benchmarks\n",
      "      copying vllm\\benchmarks\\endpoint_request_func.py -> build\\lib\\vllm\\benchmarks\n",
      "      copying vllm\\benchmarks\\latency.py -> build\\lib\\vllm\\benchmarks\n",
      "      copying vllm\\benchmarks\\serve.py -> build\\lib\\vllm\\benchmarks\n",
      "      copying vllm\\benchmarks\\throughput.py -> build\\lib\\vllm\\benchmarks\n",
      "      copying vllm\\benchmarks\\utils.py -> build\\lib\\vllm\\benchmarks\n",
      "      copying vllm\\benchmarks\\__init__.py -> build\\lib\\vllm\\benchmarks\n",
      "      creating build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\backends.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\compiler_interface.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\counter.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\decorators.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\fix_functionalization.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\fusion.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\fx_utils.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\inductor_pass.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\monitor.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\multi_output_match.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\noop_elimination.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\pass_manager.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\sequence_parallelism.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\torch25_custom_graph_pass.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\vllm_inductor_pass.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\wrapper.py -> build\\lib\\vllm\\compilation\n",
      "      copying vllm\\compilation\\__init__.py -> build\\lib\\vllm\\compilation\n",
      "      creating build\\lib\\vllm\\core\n",
      "      copying vllm\\core\\block_manager.py -> build\\lib\\vllm\\core\n",
      "      copying vllm\\core\\evictor.py -> build\\lib\\vllm\\core\n",
      "      copying vllm\\core\\interfaces.py -> build\\lib\\vllm\\core\n",
      "      copying vllm\\core\\placeholder_block_space_manager.py -> build\\lib\\vllm\\core\n",
      "      copying vllm\\core\\scheduler.py -> build\\lib\\vllm\\core\n",
      "      copying vllm\\core\\__init__.py -> build\\lib\\vllm\\core\n",
      "      creating build\\lib\\vllm\\device_allocator\n",
      "      copying vllm\\device_allocator\\cumem.py -> build\\lib\\vllm\\device_allocator\n",
      "      copying vllm\\device_allocator\\__init__.py -> build\\lib\\vllm\\device_allocator\n",
      "      creating build\\lib\\vllm\\distributed\n",
      "      copying vllm\\distributed\\communication_op.py -> build\\lib\\vllm\\distributed\n",
      "      copying vllm\\distributed\\parallel_state.py -> build\\lib\\vllm\\distributed\n",
      "      copying vllm\\distributed\\utils.py -> build\\lib\\vllm\\distributed\n",
      "      copying vllm\\distributed\\__init__.py -> build\\lib\\vllm\\distributed\n",
      "      creating build\\lib\\vllm\\engine\n",
      "      copying vllm\\engine\\arg_utils.py -> build\\lib\\vllm\\engine\n",
      "      copying vllm\\engine\\async_llm_engine.py -> build\\lib\\vllm\\engine\n",
      "      copying vllm\\engine\\async_timeout.py -> build\\lib\\vllm\\engine\n",
      "      copying vllm\\engine\\llm_engine.py -> build\\lib\\vllm\\engine\n",
      "      copying vllm\\engine\\metrics.py -> build\\lib\\vllm\\engine\n",
      "      copying vllm\\engine\\metrics_types.py -> build\\lib\\vllm\\engine\n",
      "      copying vllm\\engine\\protocol.py -> build\\lib\\vllm\\engine\n",
      "      copying vllm\\engine\\__init__.py -> build\\lib\\vllm\\engine\n",
      "      creating build\\lib\\vllm\\entrypoints\n",
      "      copying vllm\\entrypoints\\api_server.py -> build\\lib\\vllm\\entrypoints\n",
      "      copying vllm\\entrypoints\\chat_utils.py -> build\\lib\\vllm\\entrypoints\n",
      "      copying vllm\\entrypoints\\launcher.py -> build\\lib\\vllm\\entrypoints\n",
      "      copying vllm\\entrypoints\\llm.py -> build\\lib\\vllm\\entrypoints\n",
      "      copying vllm\\entrypoints\\logger.py -> build\\lib\\vllm\\entrypoints\n",
      "      copying vllm\\entrypoints\\score_utils.py -> build\\lib\\vllm\\entrypoints\n",
      "      copying vllm\\entrypoints\\ssl.py -> build\\lib\\vllm\\entrypoints\n",
      "      copying vllm\\entrypoints\\utils.py -> build\\lib\\vllm\\entrypoints\n",
      "      copying vllm\\entrypoints\\__init__.py -> build\\lib\\vllm\\entrypoints\n",
      "      creating build\\lib\\vllm\\executor\n",
      "      copying vllm\\executor\\executor_base.py -> build\\lib\\vllm\\executor\n",
      "      copying vllm\\executor\\mp_distributed_executor.py -> build\\lib\\vllm\\executor\n",
      "      copying vllm\\executor\\msgspec_utils.py -> build\\lib\\vllm\\executor\n",
      "      copying vllm\\executor\\multiproc_worker_utils.py -> build\\lib\\vllm\\executor\n",
      "      copying vllm\\executor\\ray_distributed_executor.py -> build\\lib\\vllm\\executor\n",
      "      copying vllm\\executor\\ray_utils.py -> build\\lib\\vllm\\executor\n",
      "      copying vllm\\executor\\uniproc_executor.py -> build\\lib\\vllm\\executor\n",
      "      copying vllm\\executor\\__init__.py -> build\\lib\\vllm\\executor\n",
      "      creating build\\lib\\vllm\\inputs\n",
      "      copying vllm\\inputs\\data.py -> build\\lib\\vllm\\inputs\n",
      "      copying vllm\\inputs\\parse.py -> build\\lib\\vllm\\inputs\n",
      "      copying vllm\\inputs\\preprocess.py -> build\\lib\\vllm\\inputs\n",
      "      copying vllm\\inputs\\registry.py -> build\\lib\\vllm\\inputs\n",
      "      copying vllm\\inputs\\__init__.py -> build\\lib\\vllm\\inputs\n",
      "      creating build\\lib\\vllm\\logging_utils\n",
      "      copying vllm\\logging_utils\\formatter.py -> build\\lib\\vllm\\logging_utils\n",
      "      copying vllm\\logging_utils\\__init__.py -> build\\lib\\vllm\\logging_utils\n",
      "      creating build\\lib\\vllm\\lora\n",
      "      copying vllm\\lora\\fully_sharded_layers.py -> build\\lib\\vllm\\lora\n",
      "      copying vllm\\lora\\layers.py -> build\\lib\\vllm\\lora\n",
      "      copying vllm\\lora\\lora.py -> build\\lib\\vllm\\lora\n",
      "      copying vllm\\lora\\models.py -> build\\lib\\vllm\\lora\n",
      "      copying vllm\\lora\\peft_helper.py -> build\\lib\\vllm\\lora\n",
      "      copying vllm\\lora\\request.py -> build\\lib\\vllm\\lora\n",
      "      copying vllm\\lora\\resolver.py -> build\\lib\\vllm\\lora\n",
      "      copying vllm\\lora\\utils.py -> build\\lib\\vllm\\lora\n",
      "      copying vllm\\lora\\worker_manager.py -> build\\lib\\vllm\\lora\n",
      "      copying vllm\\lora\\__init__.py -> build\\lib\\vllm\\lora\n",
      "      creating build\\lib\\vllm\\model_executor\n",
      "      copying vllm\\model_executor\\custom_op.py -> build\\lib\\vllm\\model_executor\n",
      "      copying vllm\\model_executor\\parameter.py -> build\\lib\\vllm\\model_executor\n",
      "      copying vllm\\model_executor\\pooling_metadata.py -> build\\lib\\vllm\\model_executor\n",
      "      copying vllm\\model_executor\\sampling_metadata.py -> build\\lib\\vllm\\model_executor\n",
      "      copying vllm\\model_executor\\utils.py -> build\\lib\\vllm\\model_executor\n",
      "      copying vllm\\model_executor\\__init__.py -> build\\lib\\vllm\\model_executor\n",
      "      creating build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\audio.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\base.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\hasher.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\image.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\inputs.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\parse.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\processing.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\profiling.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\registry.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\utils.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\video.py -> build\\lib\\vllm\\multimodal\n",
      "      copying vllm\\multimodal\\__init__.py -> build\\lib\\vllm\\multimodal\n",
      "      creating build\\lib\\vllm\\platforms\n",
      "      copying vllm\\platforms\\cpu.py -> build\\lib\\vllm\\platforms\n",
      "      copying vllm\\platforms\\cuda.py -> build\\lib\\vllm\\platforms\n",
      "      copying vllm\\platforms\\hpu.py -> build\\lib\\vllm\\platforms\n",
      "      copying vllm\\platforms\\interface.py -> build\\lib\\vllm\\platforms\n",
      "      copying vllm\\platforms\\neuron.py -> build\\lib\\vllm\\platforms\n",
      "      copying vllm\\platforms\\rocm.py -> build\\lib\\vllm\\platforms\n",
      "      copying vllm\\platforms\\tpu.py -> build\\lib\\vllm\\platforms\n",
      "      copying vllm\\platforms\\xpu.py -> build\\lib\\vllm\\platforms\n",
      "      copying vllm\\platforms\\__init__.py -> build\\lib\\vllm\\platforms\n",
      "      creating build\\lib\\vllm\\plugins\n",
      "      copying vllm\\plugins\\__init__.py -> build\\lib\\vllm\\plugins\n",
      "      creating build\\lib\\vllm\\profiler\n",
      "      copying vllm\\profiler\\layerwise_profile.py -> build\\lib\\vllm\\profiler\n",
      "      copying vllm\\profiler\\utils.py -> build\\lib\\vllm\\profiler\n",
      "      copying vllm\\profiler\\__init__.py -> build\\lib\\vllm\\profiler\n",
      "      creating build\\lib\\vllm\\prompt_adapter\n",
      "      copying vllm\\prompt_adapter\\layers.py -> build\\lib\\vllm\\prompt_adapter\n",
      "      copying vllm\\prompt_adapter\\models.py -> build\\lib\\vllm\\prompt_adapter\n",
      "      copying vllm\\prompt_adapter\\request.py -> build\\lib\\vllm\\prompt_adapter\n",
      "      copying vllm\\prompt_adapter\\utils.py -> build\\lib\\vllm\\prompt_adapter\n",
      "      copying vllm\\prompt_adapter\\worker_manager.py -> build\\lib\\vllm\\prompt_adapter\n",
      "      copying vllm\\prompt_adapter\\__init__.py -> build\\lib\\vllm\\prompt_adapter\n",
      "      creating build\\lib\\vllm\\reasoning\n",
      "      copying vllm\\reasoning\\abs_reasoning_parsers.py -> build\\lib\\vllm\\reasoning\n",
      "      copying vllm\\reasoning\\deepseek_r1_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
      "      copying vllm\\reasoning\\granite_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
      "      copying vllm\\reasoning\\__init__.py -> build\\lib\\vllm\\reasoning\n",
      "      creating build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\batch_expansion.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\draft_model_runner.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\interfaces.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\medusa_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\metrics.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\mlp_speculator_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\mqa_scorer.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\multi_step_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\ngram_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\proposer_worker_base.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\smaller_tp_proposer_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\spec_decode_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\target_model_runner.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\top1_proposer.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\util.py -> build\\lib\\vllm\\spec_decode\n",
      "      copying vllm\\spec_decode\\__init__.py -> build\\lib\\vllm\\spec_decode\n",
      "      creating build\\lib\\vllm\\third_party\n",
      "      copying vllm\\third_party\\pynvml.py -> build\\lib\\vllm\\third_party\n",
      "      copying vllm\\third_party\\__init__.py -> build\\lib\\vllm\\third_party\n",
      "      creating build\\lib\\vllm\\transformers_utils\n",
      "      copying vllm\\transformers_utils\\config.py -> build\\lib\\vllm\\transformers_utils\n",
      "      copying vllm\\transformers_utils\\detokenizer.py -> build\\lib\\vllm\\transformers_utils\n",
      "      copying vllm\\transformers_utils\\detokenizer_utils.py -> build\\lib\\vllm\\transformers_utils\n",
      "      copying vllm\\transformers_utils\\processor.py -> build\\lib\\vllm\\transformers_utils\n",
      "      copying vllm\\transformers_utils\\s3_utils.py -> build\\lib\\vllm\\transformers_utils\n",
      "      copying vllm\\transformers_utils\\tokenizer.py -> build\\lib\\vllm\\transformers_utils\n",
      "      copying vllm\\transformers_utils\\tokenizer_base.py -> build\\lib\\vllm\\transformers_utils\n",
      "      copying vllm\\transformers_utils\\tokenizer_group.py -> build\\lib\\vllm\\transformers_utils\n",
      "      copying vllm\\transformers_utils\\utils.py -> build\\lib\\vllm\\transformers_utils\n",
      "      copying vllm\\transformers_utils\\__init__.py -> build\\lib\\vllm\\transformers_utils\n",
      "      creating build\\lib\\vllm\\triton_utils\n",
      "      copying vllm\\triton_utils\\importing.py -> build\\lib\\vllm\\triton_utils\n",
      "      copying vllm\\triton_utils\\__init__.py -> build\\lib\\vllm\\triton_utils\n",
      "      creating build\\lib\\vllm\\usage\n",
      "      copying vllm\\usage\\usage_lib.py -> build\\lib\\vllm\\usage\n",
      "      copying vllm\\usage\\__init__.py -> build\\lib\\vllm\\usage\n",
      "      creating build\\lib\\vllm\\v1\n",
      "      copying vllm\\v1\\kv_cache_interface.py -> build\\lib\\vllm\\v1\n",
      "      copying vllm\\v1\\outputs.py -> build\\lib\\vllm\\v1\n",
      "      copying vllm\\v1\\request.py -> build\\lib\\vllm\\v1\n",
      "      copying vllm\\v1\\serial_utils.py -> build\\lib\\vllm\\v1\n",
      "      copying vllm\\v1\\utils.py -> build\\lib\\vllm\\v1\n",
      "      copying vllm\\v1\\__init__.py -> build\\lib\\vllm\\v1\n",
      "      creating build\\lib\\vllm\\vllm_flash_attn\n",
      "      copying vllm\\vllm_flash_attn\\flash_attn_interface.py -> build\\lib\\vllm\\vllm_flash_attn\n",
      "      copying vllm\\vllm_flash_attn\\__init__.py -> build\\lib\\vllm\\vllm_flash_attn\n",
      "      creating build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\cache_engine.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\cpu_enc_dec_model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\cpu_model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\cpu_pooling_model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\cpu_worker.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\enc_dec_model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\hpu_model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\hpu_worker.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\model_runner_base.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\multi_step_hpu_worker.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\multi_step_model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\multi_step_tpu_worker.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\multi_step_worker.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\neuron_model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\neuron_worker.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\pooling_model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\tpu_model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\tpu_worker.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\utils.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\worker.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\worker_base.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\xpu_model_runner.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\xpu_worker.py -> build\\lib\\vllm\\worker\n",
      "      copying vllm\\worker\\__init__.py -> build\\lib\\vllm\\worker\n",
      "      creating build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\abstract.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\blocksparse_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\cpu_mla.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\flashinfer.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\flashmla.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\flash_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\hpu_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\ipex_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\pallas.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\placeholder_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\rocm_aiter_mla.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\rocm_flash_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\torch_sdpa.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\triton_mla.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\utils.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\xformers.py -> build\\lib\\vllm\\attention\\backends\n",
      "      copying vllm\\attention\\backends\\__init__.py -> build\\lib\\vllm\\attention\\backends\n",
      "      creating build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\chunked_prefill_paged_decode.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\flashmla.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\hpu_paged_attn.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\ipex_attn.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\merge_attn_states.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\nki_flash_attn.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\paged_attn.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\prefix_prefill.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\rocm_aiter_mla.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\rocm_aiter_paged_attn.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\triton_decode_attention.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\triton_flash_attention.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\triton_merge_attn_states.py -> build\\lib\\vllm\\attention\\ops\n",
      "      copying vllm\\attention\\ops\\__init__.py -> build\\lib\\vllm\\attention\\ops\n",
      "      creating build\\lib\\vllm\\attention\\utils\n",
      "      copying vllm\\attention\\utils\\fa_utils.py -> build\\lib\\vllm\\attention\\utils\n",
      "      creating build\\lib\\vllm\\attention\\backends\\mla\n",
      "      copying vllm\\attention\\backends\\mla\\common.py -> build\\lib\\vllm\\attention\\backends\\mla\n",
      "      copying vllm\\attention\\backends\\mla\\__init__.py -> build\\lib\\vllm\\attention\\backends\\mla\n",
      "      creating build\\lib\\vllm\\attention\\ops\\blocksparse_attention\n",
      "      copying vllm\\attention\\ops\\blocksparse_attention\\blocksparse_attention_kernel.py -> build\\lib\\vllm\\attention\\ops\\blocksparse_attention\n",
      "      copying vllm\\attention\\ops\\blocksparse_attention\\interface.py -> build\\lib\\vllm\\attention\\ops\\blocksparse_attention\n",
      "      copying vllm\\attention\\ops\\blocksparse_attention\\utils.py -> build\\lib\\vllm\\attention\\ops\\blocksparse_attention\n",
      "      copying vllm\\attention\\ops\\blocksparse_attention\\__init__.py -> build\\lib\\vllm\\attention\\ops\\blocksparse_attention\n",
      "      creating build\\lib\\vllm\\core\\block\n",
      "      copying vllm\\core\\block\\block_table.py -> build\\lib\\vllm\\core\\block\n",
      "      copying vllm\\core\\block\\common.py -> build\\lib\\vllm\\core\\block\n",
      "      copying vllm\\core\\block\\cpu_gpu_block_allocator.py -> build\\lib\\vllm\\core\\block\n",
      "      copying vllm\\core\\block\\interfaces.py -> build\\lib\\vllm\\core\\block\n",
      "      copying vllm\\core\\block\\naive_block.py -> build\\lib\\vllm\\core\\block\n",
      "      copying vllm\\core\\block\\prefix_caching_block.py -> build\\lib\\vllm\\core\\block\n",
      "      copying vllm\\core\\block\\utils.py -> build\\lib\\vllm\\core\\block\n",
      "      copying vllm\\core\\block\\__init__.py -> build\\lib\\vllm\\core\\block\n",
      "      creating build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\base_device_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\cpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\cuda_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\cuda_wrapper.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\custom_all_reduce.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\custom_all_reduce_utils.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\hpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\neuron_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\pynccl.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\pynccl_wrapper.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\shm_broadcast.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\tpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\xpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      copying vllm\\distributed\\device_communicators\\__init__.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "      creating build\\lib\\vllm\\distributed\\kv_transfer\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector_agent.py -> build\\lib\\vllm\\distributed\\kv_transfer\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_transfer_state.py -> build\\lib\\vllm\\distributed\\kv_transfer\n",
      "      copying vllm\\distributed\\kv_transfer\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\n",
      "      creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\factory.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\lmcache_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\mooncake_store_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\simple_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\utils.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\mooncake_store.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\simple_buffer.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "      creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_pipe\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_pipe\\mooncake_pipe.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_pipe\\pynccl_pipe.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_pipe\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "      creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\shared_storage_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
      "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
      "      creating build\\lib\\vllm\\engine\\multiprocessing\n",
      "      copying vllm\\engine\\multiprocessing\\client.py -> build\\lib\\vllm\\engine\\multiprocessing\n",
      "      copying vllm\\engine\\multiprocessing\\engine.py -> build\\lib\\vllm\\engine\\multiprocessing\n",
      "      copying vllm\\engine\\multiprocessing\\__init__.py -> build\\lib\\vllm\\engine\\multiprocessing\n",
      "      creating build\\lib\\vllm\\engine\\output_processor\n",
      "      copying vllm\\engine\\output_processor\\interfaces.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "      copying vllm\\engine\\output_processor\\multi_step.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "      copying vllm\\engine\\output_processor\\single_step.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "      copying vllm\\engine\\output_processor\\stop_checker.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "      copying vllm\\engine\\output_processor\\util.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "      copying vllm\\engine\\output_processor\\__init__.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "      creating build\\lib\\vllm\\entrypoints\\cli\n",
      "      copying vllm\\entrypoints\\cli\\collect_env.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "      copying vllm\\entrypoints\\cli\\main.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "      copying vllm\\entrypoints\\cli\\openai.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "      copying vllm\\entrypoints\\cli\\serve.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "      copying vllm\\entrypoints\\cli\\types.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "      copying vllm\\entrypoints\\cli\\__init__.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "      creating build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\api_server.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\cli_args.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\logits_processors.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\protocol.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\run_batch.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\serving_chat.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\serving_completion.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\serving_embedding.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\serving_engine.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\serving_models.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\serving_pooling.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\serving_score.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\serving_tokenization.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\serving_transcription.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      copying vllm\\entrypoints\\openai\\__init__.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "      creating build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying vllm\\entrypoints\\cli\\benchmark\\base.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying vllm\\entrypoints\\cli\\benchmark\\latency.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying vllm\\entrypoints\\cli\\benchmark\\main.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying vllm\\entrypoints\\cli\\benchmark\\serve.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying vllm\\entrypoints\\cli\\benchmark\\throughput.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying vllm\\entrypoints\\cli\\benchmark\\__init__.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
      "      creating build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\abstract_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\granite_20b_fc_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\granite_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\hermes_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\internlm2_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\jamba_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\llama_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\mistral_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\phi4mini_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\pythonic_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\utils.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying vllm\\entrypoints\\openai\\tool_parsers\\__init__.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      creating build\\lib\\vllm\\lora\\ops\n",
      "      copying vllm\\lora\\ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\n",
      "      creating build\\lib\\vllm\\lora\\punica_wrapper\n",
      "      copying vllm\\lora\\punica_wrapper\\punica_base.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "      copying vllm\\lora\\punica_wrapper\\punica_cpu.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "      copying vllm\\lora\\punica_wrapper\\punica_gpu.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "      copying vllm\\lora\\punica_wrapper\\punica_hpu.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "      copying vllm\\lora\\punica_wrapper\\punica_selector.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "      copying vllm\\lora\\punica_wrapper\\utils.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "      copying vllm\\lora\\punica_wrapper\\__init__.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "      creating build\\lib\\vllm\\lora\\ops\\torch_ops\n",
      "      copying vllm\\lora\\ops\\torch_ops\\lora_ops.py -> build\\lib\\vllm\\lora\\ops\\torch_ops\n",
      "      copying vllm\\lora\\ops\\torch_ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\\torch_ops\n",
      "      creating build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "      copying vllm\\lora\\ops\\triton_ops\\kernel_utils.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "      copying vllm\\lora\\ops\\triton_ops\\lora_expand.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "      copying vllm\\lora\\ops\\triton_ops\\lora_kernel_metadata.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "      copying vllm\\lora\\ops\\triton_ops\\lora_shrink.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "      copying vllm\\lora\\ops\\triton_ops\\utils.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "      copying vllm\\lora\\ops\\triton_ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "      creating build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "      copying vllm\\model_executor\\guided_decoding\\guidance_decoding.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "      copying vllm\\model_executor\\guided_decoding\\guidance_logits_processors.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "      copying vllm\\model_executor\\guided_decoding\\guided_fields.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "      copying vllm\\model_executor\\guided_decoding\\lm_format_enforcer_decoding.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "      copying vllm\\model_executor\\guided_decoding\\outlines_decoding.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "      copying vllm\\model_executor\\guided_decoding\\outlines_logits_processors.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "      copying vllm\\model_executor\\guided_decoding\\utils.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "      copying vllm\\model_executor\\guided_decoding\\xgrammar_decoding.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "      copying vllm\\model_executor\\guided_decoding\\__init__.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\activation.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\layernorm.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\lightning_attn.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\linear.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\logits_processor.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\pooler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\rejection_sampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\resampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\rotary_embedding.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\sampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\spec_decode_base_sampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\typical_acceptance_sampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\utils.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\vocab_parallel_embedding.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      copying vllm\\model_executor\\layers\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "      creating build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\adapters.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\arctic.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\aria.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\aya_vision.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\baichuan.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\bamba.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\bart.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\bert.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\blip.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\blip2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\bloom.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\chameleon.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\chatglm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\clip.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\commandr.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\constant_size_cache.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\dbrx.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\deepseek.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\deepseek_mtp.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\deepseek_v2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\deepseek_vl2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\eagle.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\exaone.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\fairseq2_llama.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\falcon.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\florence2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\fuyu.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\gemma.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\gemma2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\gemma3.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\gemma3_mm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\glm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\glm4.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\glm4v.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\gpt2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\gpt_bigcode.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\gpt_j.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\gpt_neox.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\granite.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\granitemoe.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\granitemoeshared.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\granite_speech.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\gritlm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\grok1.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\h2ovl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\idefics2_vision_model.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\idefics3.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\interfaces.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\interfaces_base.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\internlm2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\internlm2_ve.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\internvl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\intern_vit.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\jais.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\jamba.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\kimi_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\llama.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\llama4.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\llama_eagle.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\llama_eagle3.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\llava.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\llava_next.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\llava_next_video.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\llava_onevision.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\mamba.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\mamba2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\mamba_cache.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\medusa.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\minicpm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\minicpm3.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\minicpmo.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\minicpmv.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\minimax_cache.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\minimax_text_01.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\mistral3.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\mixtral.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\mixtral_quant.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\mllama.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\mllama4.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\mlp_speculator.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\modernbert.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\module_mapping.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\molmo.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\moonvit.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\mpt.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\nemotron.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\nemotron_nas.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\nvlm_d.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\olmo.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\olmo2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\olmoe.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\opt.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\orion.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\paligemma.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\persimmon.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\phi.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\phi3.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\phi3v.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\phi3_small.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\phi4mm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\phi4mm_audio.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\phi4mm_utils.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\phimoe.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\pixtral.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\plamo2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\prithvi_geospatial_mae.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen2_5_omni_thinker.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen2_5_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen2_audio.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen2_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen2_rm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen2_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen3.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen3_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\qwen_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\registry.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\roberta.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\siglip.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\skyworkr1v.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\smolvlm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\solar.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\stablelm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\starcoder2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\telechat2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\teleflm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\transformers.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\ultravox.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\utils.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\vision.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\whisper.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\zamba2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      copying vllm\\model_executor\\models\\__init__.py -> build\\lib\\vllm\\model_executor\\models\n",
      "      creating build\\lib\\vllm\\model_executor\\model_loader\n",
      "      copying vllm\\model_executor\\model_loader\\loader.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "      copying vllm\\model_executor\\model_loader\\neuron.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "      copying vllm\\model_executor\\model_loader\\tensorizer.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "      copying vllm\\model_executor\\model_loader\\utils.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "      copying vllm\\model_executor\\model_loader\\weight_utils.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "      copying vllm\\model_executor\\model_loader\\__init__.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "      creating build\\lib\\vllm\\model_executor\\guided_decoding\\reasoner\n",
      "      copying vllm\\model_executor\\guided_decoding\\reasoner\\__init__.py -> build\\lib\\vllm\\model_executor\\guided_decoding\\reasoner\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\cutlass_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\deep_gemm_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\fused_marlin_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\fused_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\layer.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\moe_align_block_size.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\moe_pallas.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\moe_torch_iterative.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\rocm_aiter_fused_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\utils.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\mamba\n",
      "      copying vllm\\model_executor\\layers\\mamba\\mamba2_metadata.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
      "      copying vllm\\model_executor\\layers\\mamba\\mamba_mixer.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
      "      copying vllm\\model_executor\\layers\\mamba\\mamba_mixer2.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
      "      copying vllm\\model_executor\\layers\\mamba\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\aqlm.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\awq.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\awq_marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\awq_triton.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\base_config.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\bitblas.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\bitsandbytes.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\deepspeedfp.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\experts_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\fbgemm_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\gguf.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\gptq.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\gptq_bitblas.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\gptq_marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\gptq_marlin_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\hqq_marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\ipex_quant.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kv_cache.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\modelopt.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\moe_wna16.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\neuron_quant.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\ptpc_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\qqq.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\schema.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\torchao.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\tpu_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      copying vllm\\model_executor\\layers\\quantization\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "      copying vllm\\model_executor\\layers\\mamba\\ops\\causal_conv1d.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "      copying vllm\\model_executor\\layers\\mamba\\ops\\mamba_ssm.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "      copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_bmm.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "      copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_chunk_scan.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "      copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_chunk_state.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "      copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_combined.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "      copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_state_passing.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "      copying vllm\\model_executor\\layers\\mamba\\ops\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\compressed_tensors.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\compressed_tensors_moe.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\triton_scaled_mm.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "      copying vllm\\model_executor\\layers\\quantization\\quark\\quark.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "      copying vllm\\model_executor\\layers\\quantization\\quark\\quark_moe.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "      copying vllm\\model_executor\\layers\\quantization\\quark\\utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "      copying vllm\\model_executor\\layers\\quantization\\quark\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\allspark_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\bitblas_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\fp8_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\gptq_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\int8_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\layer_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\machete_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_test.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_test_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_test_qqq.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\quant_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\w8a8_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_scheme.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a16_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a16_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a8_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a8_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_wNa16.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\allspark.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\bitblas.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\exllama.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\machete.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\MPLinearKernel.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\aiter.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\cutlass.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\ScaledMMLinearKernel.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\triton.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\xla.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_scheme.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_w8a8_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_w8a8_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "      copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "      creating build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\arctic.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\chatglm.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\cohere2.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\dbrx.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\deepseek_vl2.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\eagle.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\exaone.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\falcon.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\h2ovl.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\internvl.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\jais.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\kimi_vl.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\medusa.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\mllama.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\mlp_speculator.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\moonvit.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\mpt.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\nemotron.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\nvlm_d.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\skyworkr1v.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\solar.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\telechat2.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\ultravox.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      copying vllm\\transformers_utils\\configs\\__init__.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "      creating build\\lib\\vllm\\transformers_utils\\processors\n",
      "      copying vllm\\transformers_utils\\processors\\deepseek_vl2.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
      "      copying vllm\\transformers_utils\\processors\\__init__.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
      "      creating build\\lib\\vllm\\transformers_utils\\tokenizers\n",
      "      copying vllm\\transformers_utils\\tokenizers\\mistral.py -> build\\lib\\vllm\\transformers_utils\\tokenizers\n",
      "      copying vllm\\transformers_utils\\tokenizers\\__init__.py -> build\\lib\\vllm\\transformers_utils\\tokenizers\n",
      "      creating build\\lib\\vllm\\v1\\attention\n",
      "      copying vllm\\v1\\attention\\__init__.py -> build\\lib\\vllm\\v1\\attention\n",
      "      creating build\\lib\\vllm\\v1\\core\n",
      "      copying vllm\\v1\\core\\block_pool.py -> build\\lib\\vllm\\v1\\core\n",
      "      copying vllm\\v1\\core\\encoder_cache_manager.py -> build\\lib\\vllm\\v1\\core\n",
      "      copying vllm\\v1\\core\\kv_cache_manager.py -> build\\lib\\vllm\\v1\\core\n",
      "      copying vllm\\v1\\core\\kv_cache_utils.py -> build\\lib\\vllm\\v1\\core\n",
      "      copying vllm\\v1\\core\\specialized_manager.py -> build\\lib\\vllm\\v1\\core\n",
      "      copying vllm\\v1\\core\\__init__.py -> build\\lib\\vllm\\v1\\core\n",
      "      creating build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\async_llm.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\core.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\core_client.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\detokenizer.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\exceptions.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\llm_engine.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\logprobs.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\mm_input_cache.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\output_processor.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\parallel_sampling.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\processor.py -> build\\lib\\vllm\\v1\\engine\n",
      "      copying vllm\\v1\\engine\\__init__.py -> build\\lib\\vllm\\v1\\engine\n",
      "      creating build\\lib\\vllm\\v1\\executor\n",
      "      copying vllm\\v1\\executor\\abstract.py -> build\\lib\\vllm\\v1\\executor\n",
      "      copying vllm\\v1\\executor\\multiproc_executor.py -> build\\lib\\vllm\\v1\\executor\n",
      "      copying vllm\\v1\\executor\\ray_distributed_executor.py -> build\\lib\\vllm\\v1\\executor\n",
      "      copying vllm\\v1\\executor\\__init__.py -> build\\lib\\vllm\\v1\\executor\n",
      "      creating build\\lib\\vllm\\v1\\metrics\n",
      "      copying vllm\\v1\\metrics\\loggers.py -> build\\lib\\vllm\\v1\\metrics\n",
      "      copying vllm\\v1\\metrics\\stats.py -> build\\lib\\vllm\\v1\\metrics\n",
      "      copying vllm\\v1\\metrics\\__init__.py -> build\\lib\\vllm\\v1\\metrics\n",
      "      creating build\\lib\\vllm\\v1\\sample\n",
      "      copying vllm\\v1\\sample\\metadata.py -> build\\lib\\vllm\\v1\\sample\n",
      "      copying vllm\\v1\\sample\\rejection_sampler.py -> build\\lib\\vllm\\v1\\sample\n",
      "      copying vllm\\v1\\sample\\sampler.py -> build\\lib\\vllm\\v1\\sample\n",
      "      copying vllm\\v1\\sample\\__init__.py -> build\\lib\\vllm\\v1\\sample\n",
      "      creating build\\lib\\vllm\\v1\\spec_decode\n",
      "      copying vllm\\v1\\spec_decode\\eagle.py -> build\\lib\\vllm\\v1\\spec_decode\n",
      "      copying vllm\\v1\\spec_decode\\metadata.py -> build\\lib\\vllm\\v1\\spec_decode\n",
      "      copying vllm\\v1\\spec_decode\\metrics.py -> build\\lib\\vllm\\v1\\spec_decode\n",
      "      copying vllm\\v1\\spec_decode\\ngram_proposer.py -> build\\lib\\vllm\\v1\\spec_decode\n",
      "      copying vllm\\v1\\spec_decode\\utils.py -> build\\lib\\vllm\\v1\\spec_decode\n",
      "      copying vllm\\v1\\spec_decode\\__init__.py -> build\\lib\\vllm\\v1\\spec_decode\n",
      "      creating build\\lib\\vllm\\v1\\stats\n",
      "      copying vllm\\v1\\stats\\common.py -> build\\lib\\vllm\\v1\\stats\n",
      "      copying vllm\\v1\\stats\\__init__.py -> build\\lib\\vllm\\v1\\stats\n",
      "      creating build\\lib\\vllm\\v1\\structured_output\n",
      "      copying vllm\\v1\\structured_output\\backend_guidance.py -> build\\lib\\vllm\\v1\\structured_output\n",
      "      copying vllm\\v1\\structured_output\\backend_types.py -> build\\lib\\vllm\\v1\\structured_output\n",
      "      copying vllm\\v1\\structured_output\\backend_xgrammar.py -> build\\lib\\vllm\\v1\\structured_output\n",
      "      copying vllm\\v1\\structured_output\\request.py -> build\\lib\\vllm\\v1\\structured_output\n",
      "      copying vllm\\v1\\structured_output\\utils.py -> build\\lib\\vllm\\v1\\structured_output\n",
      "      copying vllm\\v1\\structured_output\\__init__.py -> build\\lib\\vllm\\v1\\structured_output\n",
      "      creating build\\lib\\vllm\\v1\\worker\n",
      "      copying vllm\\v1\\worker\\block_table.py -> build\\lib\\vllm\\v1\\worker\n",
      "      copying vllm\\v1\\worker\\gpu_input_batch.py -> build\\lib\\vllm\\v1\\worker\n",
      "      copying vllm\\v1\\worker\\gpu_model_runner.py -> build\\lib\\vllm\\v1\\worker\n",
      "      copying vllm\\v1\\worker\\gpu_worker.py -> build\\lib\\vllm\\v1\\worker\n",
      "      copying vllm\\v1\\worker\\lora_model_runner_mixin.py -> build\\lib\\vllm\\v1\\worker\n",
      "      copying vllm\\v1\\worker\\tpu_model_runner.py -> build\\lib\\vllm\\v1\\worker\n",
      "      copying vllm\\v1\\worker\\tpu_worker.py -> build\\lib\\vllm\\v1\\worker\n",
      "      copying vllm\\v1\\worker\\utils.py -> build\\lib\\vllm\\v1\\worker\n",
      "      copying vllm\\v1\\worker\\worker_base.py -> build\\lib\\vllm\\v1\\worker\n",
      "      copying vllm\\v1\\worker\\__init__.py -> build\\lib\\vllm\\v1\\worker\n",
      "      creating build\\lib\\vllm\\v1\\attention\\backends\n",
      "      copying vllm\\v1\\attention\\backends\\flashinfer.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
      "      copying vllm\\v1\\attention\\backends\\flash_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
      "      copying vllm\\v1\\attention\\backends\\pallas.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
      "      copying vllm\\v1\\attention\\backends\\triton_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
      "      copying vllm\\v1\\attention\\backends\\__init__.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
      "      creating build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
      "      copying vllm\\v1\\attention\\backends\\mla\\common.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
      "      copying vllm\\v1\\attention\\backends\\mla\\flashmla.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
      "      copying vllm\\v1\\attention\\backends\\mla\\triton_mla.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
      "      copying vllm\\v1\\attention\\backends\\mla\\__init__.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
      "      creating build\\lib\\vllm\\v1\\core\\sched\n",
      "      copying vllm\\v1\\core\\sched\\interface.py -> build\\lib\\vllm\\v1\\core\\sched\n",
      "      copying vllm\\v1\\core\\sched\\output.py -> build\\lib\\vllm\\v1\\core\\sched\n",
      "      copying vllm\\v1\\core\\sched\\scheduler.py -> build\\lib\\vllm\\v1\\core\\sched\n",
      "      copying vllm\\v1\\core\\sched\\utils.py -> build\\lib\\vllm\\v1\\core\\sched\n",
      "      copying vllm\\v1\\core\\sched\\__init__.py -> build\\lib\\vllm\\v1\\core\\sched\n",
      "      creating build\\lib\\vllm\\v1\\sample\\ops\n",
      "      copying vllm\\v1\\sample\\ops\\bad_words.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
      "      copying vllm\\v1\\sample\\ops\\penalties.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
      "      copying vllm\\v1\\sample\\ops\\topk_topp_sampler.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
      "      copying vllm\\v1\\sample\\ops\\__init__.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
      "      creating build\\lib\\vllm\\v1\\sample\\tpu\n",
      "      copying vllm\\v1\\sample\\tpu\\metadata.py -> build\\lib\\vllm\\v1\\sample\\tpu\n",
      "      copying vllm\\v1\\sample\\tpu\\sampler.py -> build\\lib\\vllm\\v1\\sample\\tpu\n",
      "      copying vllm\\v1\\sample\\tpu\\__init__.py -> build\\lib\\vllm\\v1\\sample\\tpu\n",
      "      running egg_info\n",
      "      writing vllm.egg-info\\PKG-INFO\n",
      "      writing dependency_links to vllm.egg-info\\dependency_links.txt\n",
      "      writing entry points to vllm.egg-info\\entry_points.txt\n",
      "      writing requirements to vllm.egg-info\\requires.txt\n",
      "      writing top-level names to vllm.egg-info\\top_level.txt\n",
      "      ERROR setuptools_scm._file_finders.git listing git files failed - pretending there aren't any\n",
      "      reading manifest file 'vllm.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      adding license file 'LICENSE'\n",
      "      writing manifest file 'vllm.egg-info\\SOURCES.txt'\n",
      "      copying vllm\\py.typed -> build\\lib\\vllm\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=96,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_H100.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=2560,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_L40S.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "      copying vllm\\vllm_flash_attn\\.gitkeep -> build\\lib\\vllm\\vllm_flash_attn\n",
      "      copying vllm\\distributed\\kv_transfer\\README.md -> build\\lib\\vllm\\distributed\\kv_transfer\n",
      "      copying vllm\\distributed\\kv_transfer\\disagg_prefill_workflow.jpg -> build\\lib\\vllm\\distributed\\kv_transfer\n",
      "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\README -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      installing to build\\bdist.win-amd64\\wheel\n",
      "      running install\n",
      "      running install_lib\n",
      "      creating build\\bdist.win-amd64\\wheel\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\adapter_commons\n",
      "      copying build\\lib\\vllm\\adapter_commons\\layers.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "      copying build\\lib\\vllm\\adapter_commons\\models.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "      copying build\\lib\\vllm\\adapter_commons\\request.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "      copying build\\lib\\vllm\\adapter_commons\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "      copying build\\lib\\vllm\\adapter_commons\\worker_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "      copying build\\lib\\vllm\\adapter_commons\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\assets\n",
      "      copying build\\lib\\vllm\\assets\\audio.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
      "      copying build\\lib\\vllm\\assets\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
      "      copying build\\lib\\vllm\\assets\\image.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
      "      copying build\\lib\\vllm\\assets\\video.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
      "      copying build\\lib\\vllm\\assets\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\abstract.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\blocksparse_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\cpu_mla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\flashinfer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\flashmla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\flash_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\hpu_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\ipex_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\backends\\mla\n",
      "      copying build\\lib\\vllm\\attention\\backends\\mla\\common.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\\mla\n",
      "      copying build\\lib\\vllm\\attention\\backends\\mla\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\\mla\n",
      "      copying build\\lib\\vllm\\attention\\backends\\pallas.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\placeholder_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\rocm_aiter_mla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\rocm_flash_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\torch_sdpa.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\triton_mla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\xformers.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\backends\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "      copying build\\lib\\vllm\\attention\\layer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\ops\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\ops\\blocksparse_attention\n",
      "      copying build\\lib\\vllm\\attention\\ops\\blocksparse_attention\\blocksparse_attention_kernel.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\\blocksparse_attention\n",
      "      copying build\\lib\\vllm\\attention\\ops\\blocksparse_attention\\interface.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\\blocksparse_attention\n",
      "      copying build\\lib\\vllm\\attention\\ops\\blocksparse_attention\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\\blocksparse_attention\n",
      "      copying build\\lib\\vllm\\attention\\ops\\blocksparse_attention\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\\blocksparse_attention\n",
      "      copying build\\lib\\vllm\\attention\\ops\\chunked_prefill_paged_decode.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\flashmla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\hpu_paged_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\ipex_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\merge_attn_states.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\nki_flash_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\paged_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\prefix_prefill.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\rocm_aiter_mla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\rocm_aiter_paged_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\triton_decode_attention.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\triton_flash_attention.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\triton_merge_attn_states.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "      copying build\\lib\\vllm\\attention\\selector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\utils\n",
      "      copying build\\lib\\vllm\\attention\\utils\\fa_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\utils\n",
      "      copying build\\lib\\vllm\\attention\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\n",
      "      copying build\\lib\\vllm\\beam_search.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\benchmarks\n",
      "      copying build\\lib\\vllm\\benchmarks\\datasets.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
      "      copying build\\lib\\vllm\\benchmarks\\endpoint_request_func.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
      "      copying build\\lib\\vllm\\benchmarks\\latency.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
      "      copying build\\lib\\vllm\\benchmarks\\serve.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
      "      copying build\\lib\\vllm\\benchmarks\\throughput.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
      "      copying build\\lib\\vllm\\benchmarks\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
      "      copying build\\lib\\vllm\\benchmarks\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
      "      copying build\\lib\\vllm\\collect_env.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\backends.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\compiler_interface.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\counter.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\decorators.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\fix_functionalization.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\fusion.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\fx_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\inductor_pass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\monitor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\multi_output_match.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\noop_elimination.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\pass_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\sequence_parallelism.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\torch25_custom_graph_pass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\vllm_inductor_pass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\wrapper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\compilation\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "      copying build\\lib\\vllm\\config.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "      copying build\\lib\\vllm\\connections.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\core\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\core\\block\n",
      "      copying build\\lib\\vllm\\core\\block\\block_table.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "      copying build\\lib\\vllm\\core\\block\\common.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "      copying build\\lib\\vllm\\core\\block\\cpu_gpu_block_allocator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "      copying build\\lib\\vllm\\core\\block\\interfaces.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "      copying build\\lib\\vllm\\core\\block\\naive_block.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "      copying build\\lib\\vllm\\core\\block\\prefix_caching_block.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "      copying build\\lib\\vllm\\core\\block\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "      copying build\\lib\\vllm\\core\\block\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "      copying build\\lib\\vllm\\core\\block_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "      copying build\\lib\\vllm\\core\\evictor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "      copying build\\lib\\vllm\\core\\interfaces.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "      copying build\\lib\\vllm\\core\\placeholder_block_space_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "      copying build\\lib\\vllm\\core\\scheduler.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "      copying build\\lib\\vllm\\core\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\device_allocator\n",
      "      copying build\\lib\\vllm\\device_allocator\\cumem.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\device_allocator\n",
      "      copying build\\lib\\vllm\\device_allocator\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\device_allocator\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\n",
      "      copying build\\lib\\vllm\\distributed\\communication_op.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\base_device_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\cpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\cuda_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\cuda_wrapper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\custom_all_reduce.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\custom_all_reduce_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\hpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\neuron_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\pynccl.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\pynccl_wrapper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\shm_broadcast.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\tpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\xpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      copying build\\lib\\vllm\\distributed\\device_communicators\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\disagg_prefill_workflow.jpg -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\factory.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\lmcache_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\mooncake_store_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\simple_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\shared_storage_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector_agent.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\mooncake_store.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\simple_buffer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\mooncake_pipe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\pynccl_pipe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_transfer_state.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\README.md -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
      "      copying build\\lib\\vllm\\distributed\\kv_transfer\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
      "      copying build\\lib\\vllm\\distributed\\parallel_state.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
      "      copying build\\lib\\vllm\\distributed\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
      "      copying build\\lib\\vllm\\distributed\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\engine\n",
      "      copying build\\lib\\vllm\\engine\\arg_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "      copying build\\lib\\vllm\\engine\\async_llm_engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "      copying build\\lib\\vllm\\engine\\async_timeout.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "      copying build\\lib\\vllm\\engine\\llm_engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "      copying build\\lib\\vllm\\engine\\metrics.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "      copying build\\lib\\vllm\\engine\\metrics_types.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\engine\\multiprocessing\n",
      "      copying build\\lib\\vllm\\engine\\multiprocessing\\client.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\multiprocessing\n",
      "      copying build\\lib\\vllm\\engine\\multiprocessing\\engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\multiprocessing\n",
      "      copying build\\lib\\vllm\\engine\\multiprocessing\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\multiprocessing\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\engine\\output_processor\n",
      "      copying build\\lib\\vllm\\engine\\output_processor\\interfaces.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "      copying build\\lib\\vllm\\engine\\output_processor\\multi_step.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "      copying build\\lib\\vllm\\engine\\output_processor\\single_step.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "      copying build\\lib\\vllm\\engine\\output_processor\\stop_checker.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "      copying build\\lib\\vllm\\engine\\output_processor\\util.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "      copying build\\lib\\vllm\\engine\\output_processor\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "      copying build\\lib\\vllm\\engine\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "      copying build\\lib\\vllm\\engine\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\n",
      "      copying build\\lib\\vllm\\entrypoints\\api_server.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "      copying build\\lib\\vllm\\entrypoints\\chat_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\cli\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\latency.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\main.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\serve.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\throughput.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\collect_env.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\main.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\openai.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\serve.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\types.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "      copying build\\lib\\vllm\\entrypoints\\cli\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "      copying build\\lib\\vllm\\entrypoints\\launcher.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "      copying build\\lib\\vllm\\entrypoints\\llm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "      copying build\\lib\\vllm\\entrypoints\\logger.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\api_server.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\cli_args.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\logits_processors.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\run_batch.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_chat.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_completion.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_embedding.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_models.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_pooling.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_score.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_tokenization.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_transcription.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\abstract_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\granite_20b_fc_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\granite_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\hermes_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\internlm2_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\jamba_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\llama_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\mistral_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\phi4mini_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\pythonic_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "      copying build\\lib\\vllm\\entrypoints\\openai\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "      copying build\\lib\\vllm\\entrypoints\\score_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "      copying build\\lib\\vllm\\entrypoints\\ssl.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "      copying build\\lib\\vllm\\entrypoints\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "      copying build\\lib\\vllm\\entrypoints\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "      copying build\\lib\\vllm\\envs.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "      copying build\\lib\\vllm\\env_override.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\executor\n",
      "      copying build\\lib\\vllm\\executor\\executor_base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "      copying build\\lib\\vllm\\executor\\mp_distributed_executor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "      copying build\\lib\\vllm\\executor\\msgspec_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "      copying build\\lib\\vllm\\executor\\multiproc_worker_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "      copying build\\lib\\vllm\\executor\\ray_distributed_executor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "      copying build\\lib\\vllm\\executor\\ray_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "      copying build\\lib\\vllm\\executor\\uniproc_executor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "      copying build\\lib\\vllm\\executor\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "      copying build\\lib\\vllm\\forward_context.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\inputs\n",
      "      copying build\\lib\\vllm\\inputs\\data.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
      "      copying build\\lib\\vllm\\inputs\\parse.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
      "      copying build\\lib\\vllm\\inputs\\preprocess.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
      "      copying build\\lib\\vllm\\inputs\\registry.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
      "      copying build\\lib\\vllm\\inputs\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
      "      copying build\\lib\\vllm\\jsontree.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "      copying build\\lib\\vllm\\logger.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\logging_utils\n",
      "      copying build\\lib\\vllm\\logging_utils\\formatter.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\logging_utils\n",
      "      copying build\\lib\\vllm\\logging_utils\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\logging_utils\n",
      "      copying build\\lib\\vllm\\logits_process.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\n",
      "      copying build\\lib\\vllm\\lora\\fully_sharded_layers.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "      copying build\\lib\\vllm\\lora\\layers.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "      copying build\\lib\\vllm\\lora\\lora.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "      copying build\\lib\\vllm\\lora\\models.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\\torch_ops\n",
      "      copying build\\lib\\vllm\\lora\\ops\\torch_ops\\lora_ops.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\torch_ops\n",
      "      copying build\\lib\\vllm\\lora\\ops\\torch_ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\torch_ops\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\\triton_ops\n",
      "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\kernel_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\lora_expand.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\lora_kernel_metadata.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\lora_shrink.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "      copying build\\lib\\vllm\\lora\\ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\n",
      "      copying build\\lib\\vllm\\lora\\peft_helper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\punica_wrapper\n",
      "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_cpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_gpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_hpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_selector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "      copying build\\lib\\vllm\\lora\\punica_wrapper\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "      copying build\\lib\\vllm\\lora\\punica_wrapper\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "      copying build\\lib\\vllm\\lora\\request.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "      copying build\\lib\\vllm\\lora\\resolver.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "      copying build\\lib\\vllm\\lora\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "      copying build\\lib\\vllm\\lora\\worker_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "      copying build\\lib\\vllm\\lora\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\n",
      "      copying build\\lib\\vllm\\model_executor\\custom_op.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\guided_decoding\n",
      "      copying build\\lib\\vllm\\model_executor\\guided_decoding\\guidance_decoding.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "      copying build\\lib\\vllm\\model_executor\\guided_decoding\\guidance_logits_processors.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "      copying build\\lib\\vllm\\model_executor\\guided_decoding\\guided_fields.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "      copying build\\lib\\vllm\\model_executor\\guided_decoding\\lm_format_enforcer_decoding.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "      copying build\\lib\\vllm\\model_executor\\guided_decoding\\outlines_decoding.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "      copying build\\lib\\vllm\\model_executor\\guided_decoding\\outlines_logits_processors.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\guided_decoding\\reasoner\n",
      "      copying build\\lib\\vllm\\model_executor\\guided_decoding\\reasoner\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\\reasoner\n",
      "      copying build\\lib\\vllm\\model_executor\\guided_decoding\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "      copying build\\lib\\vllm\\model_executor\\guided_decoding\\xgrammar_decoding.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "      copying build\\lib\\vllm\\model_executor\\guided_decoding\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\activation.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\fused_moe\n",
      "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=96,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_H100.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "      error: could not create 'build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json': No such file or directory\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for vllm\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (vllm)\n"
     ]
    }
   ],
   "source": [
    "!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d1399b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a student . \n"
     ]
    }
   ],
   "source": [
    "def pre(text):\n",
    "    doc = nlp(text)\n",
    "    return \"\".join(token.text+\" \" for token in doc )\n",
    "    \n",
    "\n",
    "print(pre(\"I am a student.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6636a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def payload(doc):\n",
    "    headers = {\n",
    "    \"Authorization\":f\"Bearer {api_key}\",\n",
    "    }\n",
    "    payload = {\n",
    "    \"messages\": [\n",
    "               \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": doc\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"]\n",
    "         \n",
    "    else:\n",
    "        print(f\"Error: {re4sponse.status_code}\")\n",
    "        print(f\"Error: {response.text}\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92dd982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    text = input(\"Your turn:\")\n",
    "    while text != \"exit\":\n",
    "        text = input(\"Your turn:\")\n",
    "        if text == \"exit\":\n",
    "            break\n",
    "        else:\n",
    "            ll = pre(text)\n",
    "            print(payload(ll))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10414b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
